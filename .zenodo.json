{
  "title": "Geometric Interpretability: Understanding Neural Networks through Boundary Analysis",
  "description": "A framework for understanding neural networks through spatial structure rather than semantic content. We propose Geometric Boundary Analysis (GBA) for detecting knowledge boundaries in activation space, achieving 96.5% hallucination detection with perfect linear boundaries (0.3% curvature deviation, 1.000 symmetry, 148× concentration). Our grokking experiments reveal that class separation correlates more strongly with generalization (r=0.910) than boundary sharpness (r=-0.651), suggesting separation—not sharpness—may be key to generalization. The method requires only 30-second setup, <1ms inference overhead, and $0.50 cost with no model retraining.",
  "creators": [
    {
      "name": "Choi, Seungho",
      "affiliation": "Independent Researcher",
      "orcid": ""
    }
  ],
  "contributors": [],
  "keywords": [
    "interpretability",
    "neural networks",
    "geometric analysis",
    "boundary detection",
    "hallucination detection",
    "large language models",
    "epistemic uncertainty",
    "grokking",
    "generalization",
    "activation space",
    "machine learning safety"
  ],
  "license": "MIT",
  "upload_type": "software",
  "access_right": "open",
  "related_identifiers": [
    {
      "identifier": "https://github.com/madst0614/geometric-interpretability",
      "relation": "isSupplementTo",
      "scheme": "url"
    }
  ],
  "references": [
    "Elhage, N., et al. (2022). Toy models of superposition. Transformer Circuits Thread.",
    "Ji, Z., et al. (2023). Survey of hallucination in natural language generation. ACM Computing Surveys, 55(12):1–38.",
    "Elhage, N., et al. (2021). A mathematical framework for transformer circuits. Transformer Circuits Thread.",
    "Meng, K., et al. (2022). Locating and editing factual associations in GPT. NeurIPS.",
    "Bartlett, P. L., et al. (2017). Spectrally-normalized margin bounds for neural networks. NeurIPS.",
    "Power, A., et al. (2022). Grokking: Generalization beyond overfitting on small algorithmic datasets. arXiv:2201.02177."
  ],
  "grants": [],
  "communities": [
    {
      "identifier": "machine-learning"
    },
    {
      "identifier": "ai-safety"
    }
  ],
  "version": "1.0.0",
  "language": "eng",
  "dates": [
    {
      "start": "2025-01-01",
      "end": "2025-01-31",
      "type": "Collected",
      "description": "Research period"
    }
  ],
  "notes": "This repository contains the complete implementation of Geometric Boundary Analysis (GBA), including: (1) Perfect linear boundaries analysis on Mistral-7B, (2) Grokking experiments showing separation dominance over sharpness, (3) Distance-based epistemic routing achieving 96.5% detection, (4) Training dynamics revealing natural emergence of geometric structure. Total compute: ~60 hours on single GPU. Cost: <$50. All experiments designed for rapid community validation."
}